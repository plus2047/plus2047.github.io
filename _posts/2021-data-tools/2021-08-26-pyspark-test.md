---
layout: mypost
title: PySpark + unittest + pdb = ğŸš€
categories: [data, lang]
---

ï¼ˆæˆ‘ç»ˆäºä¸æ‘¸é±¼äº†ï¼Œç»ˆäºæœ‰æŠ€æœ¯æ–‡ç« æ›´æ–°äº†ã€‚ã€‚è™½ç„¶å¾ˆçŸ­ã€‚ã€‚ï¼‰

åœ¨ä½¿ç”¨ pyspark å¼€å‘æ—¶ä¸€ç›´æœ‰ä¸€ä¸ªé—®é¢˜å›°æ‰°æˆ‘ï¼špython + vscode çš„é™æ€ç±»å‹æ£€æŸ¥èƒ½åŠ›éå¸¸å¼±ï¼Œæ‰€ä»¥å†™å¥½çš„è„šæœ¬å¦‚æœä¸è¿›è¡Œæœ¬åœ°è°ƒè¯•ï¼Œæäº¤åˆ°é›†ç¾¤ä¹‹åå¸¸å¸¸å­˜åœ¨å·¨é‡ bug, é›†ç¾¤æ¯æ¬¡è¿è¡Œè€—æ—¶å¾ˆé•¿ï¼Œäºæ˜¯è°ƒè¯•-ä¿®æ”¹çš„æµç¨‹å°±ä¼šå¾ˆæ…¢ã€‚å¯å¦‚æœè¦è¿›è¡Œæœ¬åœ°è°ƒè¯•ï¼Œæ¨¡æ‹Ÿå„ç§æ•°æ®æºä¼šéå¸¸éº»çƒ¦ã€‚

æœ€è¿‘å­¦åˆ°äº†ä¸€æ¡åŸåˆ™ï¼šæ¨¡å—åŒ–ä¸ä»…æ˜¯ä¸ºäº†å¤ç”¨ï¼Œç”šè‡³ä¸»è¦ä¸æ˜¯ä¸ºäº†å¤ç”¨ï¼Œè€Œæ˜¯ä¸ºäº†åˆ’åˆ†ä¸åŒçš„æŠ½è±¡å±‚ç­‰ã€‚æ¨¡å—åŒ–éå¸¸é‡è¦çš„ä¸€ç‚¹å°±æ˜¯æ–¹ä¾¿æµ‹è¯•ã€‚å¯¹äº pyspark ä»£ç ï¼Œå¦‚æœæœ‰è‰¯å¥½çš„æ¨¡å—åŒ–ï¼Œå•å…ƒæµ‹è¯•å¯ä»¥è¦†ç›–é™¤äº†è¾“å…¥è¾“å‡ºä¹‹å¤–çš„å¤§éƒ¨åˆ†ï¼Œè¿™è¶³ä»¥è¦†ç›–å¤§éƒ¨åˆ† bug. å¦å¤–ï¼Œç›¸è¾ƒäºåœ¨æœ¬åœ°å†™å‡ ä¸ªæ•°æ®æ–‡ä»¶ç›´æ¥è¿è¡Œ pyspark è„šæœ¬è¿›è¡Œæµ‹è¯•ï¼Œä½¿ç”¨å•å…ƒæµ‹è¯•å¯ä»¥ç”¨ python ä»£ç åˆ›å»ºå‡æ•°æ®ï¼Œä¼šæ›´åŠ æ–¹ä¾¿ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„é¡¹ç›®çš„ä¾‹å­ã€‚

```py
# project structure:
# --------
# avg_item_num.py
# test/
#     __init__.py
#     test_avg_item_num.py
# --------

# average_item_num ======
from pyspark.sql import SparkSession
import pyspark.sql.functions as F

def get_avg_item_num(df):
    """df: (query, items:array[itemid])"""
    return df.agg(
        F.avg(F.size("items")).alias("avg")
    ).collect()[0]["avg"]

if __name__ == "__main__":
    with SparkSession.builder.appName("test").getOrCreate() as spark:
        tracking = spark.read.json("tracking.json")
        print(get_avg_item_num(tracking))

# test/test_avg_item_num.py ======
import unittest
from avg_item_num import *


class TestAvgItemNum(unittest.TestCase):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.spark = SparkSession.builder.appName("test").getOrCreate()
    
    def test_get_avg_item_num(self):
        df = self.spark.createDataFrame([
            {"query": 1, "itemid": 1},
            {"query": 1, "itemid": 2},
            {"query": 2, "itemid": 3},
            {"query": 2, "itemid": 4},
            {"query": 2, "itemid": 5},
            {"query": 2, "itemid": 6},
        ]).groupBy("query").agg(
            F.collect_list("itemid").alias("items"))

        self.assertAlmostEqual(get_avg_item_num(df), 3)
```

åˆ›å»ºå®Œæˆä»¥ä¸Šç›®å½•ç»“æ„ï¼Œåªéœ€è¦åœ¨æ ¹ç›®å½•ä¸‹è¿è¡Œ `python -m unittest` å³å¯å¯åŠ¨å•å…ƒæµ‹è¯•ã€‚

æ³¨æ„ï¼Œå¯¹äºä¸€èˆ¬çš„æ¨¡å—ï¼Œå­ç›®å½•ï¼ˆå­æ¨¡å—ï¼‰çš„æ–‡ä»¶ä¸­æ˜¯ä¸èƒ½ç›´æ¥ `import` ä¸Šçº§ç›®å½•ï¼ˆä¸Šçº§æ¨¡å—ï¼‰ä¸­çš„å†…å®¹çš„ï¼Œä½†å¯¹äºå•å…ƒæµ‹è¯•ï¼Œ`test` ç›®å½•çš„æ ¹ç›®å½•å¯ä»¥ `import` é¡¹ç›®æ ¹ç›®å½•ï¼Œ`unittest` æ¨¡å—ä¼šè‡ªåŠ¨æŠŠé¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° `sys.path` ä¸­ã€‚

æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç° bug, æƒ³è¦æ‰“æ–­ç‚¹æ€ä¹ˆåŠï¼Ÿå½“ç„¶å¯ä»¥ä½¿ç”¨ IDE çš„æ–­ç‚¹è°ƒè¯•ï¼Œä½† IDE æœ‰æ—¶å€™ä¸æ–¹ä¾¿è·Ÿå‘½ä»¤è¡Œé…åˆã€‚å¯ä»¥ç›´æ¥åœ¨æƒ³è¦æ‰“æ–­ç‚¹çš„åœ°æ–¹æ’å…¥ä¸€è¡Œï¼Œ

```py
import pdb; pdb.set_trace()
```

å³å¯åœ¨æ²¡æœ‰ IDE æ”¯æ´çš„æƒ…å†µä¸‹ï¼Œåœ¨ä»»ä½•ç¯å¢ƒä¸­å¯åŠ¨æ–­ç‚¹è°ƒè¯•ã€‚ç‰¹åˆ«æ˜¯å¯åŠ¨æ–­ç‚¹è°ƒè¯•åå¯ä»¥æ–¹ä¾¿çš„æ£€æŸ¥æ•°æ®æ ¼å¼ç­‰ç­‰ã€‚

æ–­ç‚¹è°ƒè¯•æœ‰æ—¶å€™èƒ½å¤Ÿå¾ˆç¥å¥‡çš„æ›¿ä»£ jupyter notebookï¼Œä¸¤è€…éƒ½èƒ½åˆ›å»ºä¸€ä¸ªå…·æœ‰ä¸Šä¸‹æ–‡çš„ç¯å¢ƒä»¥ä¾›å°è¯•ï¼Œæ–­ç‚¹è°ƒè¯•çš„ä¼˜åŠ¿æ˜¯ä»£ç å¯å¤ç”¨æ€§æ›´å¥½ï¼Œå¹¶ä¸”ä¸éœ€è¦æŠŠæƒ³è¦è°ƒè¯•çš„ä»£ç ç²˜è´´åˆ° jupyter, ç„¶åå†ç²˜è´´å›æ¥ã€‚ä½†æ–­ç‚¹è°ƒè¯•ä¹Ÿæœ‰é—®é¢˜ï¼Œå•å…ƒæµ‹è¯•è¿è¡Œåˆ°æŒ‡å®šä½ç½®ä¹Ÿæ˜¯éœ€è¦æ—¶é—´çš„ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨äº† pyspark è¿™ç±»æ¯”è¾ƒå¤æ‚çš„æ¡†æ¶åæ›´æ…¢ã€‚
